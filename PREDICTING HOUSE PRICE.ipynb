{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOUSE PRICE PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn librarys\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, Ridge\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import recall_score,precision_score,confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import  OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pandas_profiling import ProfileReport as profile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "\n",
    "from xgboost import XGBRegressor \n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"c:/Users/User/Desktop/kaggle datasets/housing dataset/\")\n",
    "df=pd.read_csv('house_train_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA EXPLORATION - pandas profiling"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pandas profiling was used to do a comprehensive explorative analysis on the dataset. This was exported in an html format for \n",
    "detail analysis/studies. The insight gathered informed the steps below in the data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile=df.profile_report(minimal=False,progress_bar=False, explorative=True, pool_size=0, samples=None,\n",
    "#                                 missing_diagrams=None, duplicates=None);\n",
    "# profile.to_file(\"output.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HANDLING MISSING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().mean().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Droping columns with more than 40% missing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.loc[: ,  df.isnull().mean()<0.40]\n",
    "\n",
    "# Dropping the id columns because it has no predictive power\n",
    "df.drop(columns=['Id'] ,axis=1, inplace=True)\n",
    "\n",
    "print(df.isnull().mean().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns=list(df.select_dtypes(include=['int64','float64']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "imp_frequent=SimpleImputer(missing_values=np.nan,strategy=\"most_frequent\")\n",
    "\n",
    "transformed_columns= make_column_transformer  (\n",
    "                                                ( imp_mean, list(df.select_dtypes(include=['int64','float64']).columns) ),\n",
    "                                                ( imp_frequent,list(df.select_dtypes(exclude=['int64','float64']).columns) ),\n",
    "                                                 remainder = 'passthrough'\n",
    "                                              )\n",
    "\n",
    "list_columns=list(df.select_dtypes(include=['int64','float64']).columns) + list(df.select_dtypes(exclude=['int64','float64']).columns)\n",
    "\n",
    "df=pd.DataFrame(transformed_columns.fit_transform(df), columns=list_columns)\n",
    "\n",
    "df[numerical_columns]=df.loc[:,numerical_columns].astype(float)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORRELATION ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Features and their correlation with the target variable\n",
    "ans=df.iloc[:,:].corr()['SalePrice'].abs()     # using the absolute values\n",
    "ans.sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=df.corr().abs().unstack().sort_values(ascending=False).drop_duplicates()\n",
    "ans.head(48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping features with correlation >=60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GrLivArea was left out because not all houses were story buildings\n",
    "df.drop(columns=['GarageArea','GarageYrBlt','TotalBsmtSF','2ndFlrSF','BedroomAbvGr','BsmtFinSF1',\n",
    "                'FullBath','HalfBath'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFORMING FEATURES - dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YearRemodAdd']=2020-df['YearRemodAdd']\n",
    "df['YearBuilt']=2020-df['YearBuilt']\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLITTING DATA INTO TARGET VARIABLE AND FEATURE SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.loc[: , ['SalePrice']]\n",
    "X=df.drop(columns=['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_CAT=X.select_dtypes(exclude=['int64','float64'])\n",
    "X_NUM=X.select_dtypes(include=['int64','float64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()\n",
    "ohe=OneHotEncoder(handle_unknown='error',sparse=False, dtype='float32' , drop='first')\n",
    "X_CAT_TRANSFORM=pd.DataFrame(ohe.fit_transform(X_CAT))\n",
    "X_CAT_TRANSFORM.columns=ohe.get_feature_names(X_CAT.columns)\n",
    "\n",
    "X_NUM_TRANSFORM_SCALED=pd.DataFrame(scaler.fit_transform(X_NUM),columns=X_NUM.columns)\n",
    "\n",
    "#  concatenating to create the feature set\n",
    "X=pd.concat(\n",
    "           [X_NUM_TRANSFORM_SCALED.reset_index(drop=True), \n",
    "            X_CAT_TRANSFORM.reset_index(drop=True)],\n",
    "            axis=1\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAPE OF CLEANED DATASET TO BE USED FOR THE MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLITTING DATASET INTO TRAIN AND TEST SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting Dataset into train set and test set ( ratio 80 : 20 )\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y, random_state=15,test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE IMPORTANCE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameter_random_forest=dict({ 'max_features': ['auto'] ,\n",
    "                               'random_state':[0] ,\n",
    "                               'n_estimators':[20]\n",
    "                             })\n",
    "\n",
    "grid_random_forest_feat=GridSearchCV (   RandomForestRegressor(), \n",
    "                                         cv=2, \n",
    "                                         param_grid=parameter_random_forest,\n",
    "                                         scoring='r2', \n",
    "                                         n_jobs=-1\n",
    "                                      )\n",
    "\n",
    "\n",
    "grid_random_forest_feat.fit(X_train,y_train)\n",
    "\n",
    "y_predicted_random=grid_random_forest_feat.predict(X_train)            # using the gridsearchcv object for prediction\n",
    "\n",
    "print('\\n R2_score \\t', grid_random_forest_feat.score(X_train , y_train),'\\n')\n",
    "pd.DataFrame(grid_random_forest_feat.cv_results_)                      # tabulating the outcome of gridsearchcv object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rand_forest=grid_random_forest_feat.best_estimator_  # passing the instance of best search\n",
    "feat_importance=pd.DataFrame(clf_rand_forest.feature_importances_).sort_values(by=0,ascending=False)\n",
    "\n",
    "\n",
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(X_train.columns,clf_rand_forest.feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "ans=pd.DataFrame(feats,index=np.arange(len(feats)))\n",
    "ans=(ans.T)\n",
    "ans=ans.sort_values(by=0,ascending=False)\n",
    "feat_importance=pd.DataFrame(ans.loc[:,0])\n",
    "feat_importance.columns=['features']\n",
    "print('List of features according to their importance in descending order')\n",
    "feat_importance.head(18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE IMPORTANCE RANKING  - GRAPHICAL REPRESENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is the code snippet to plot the n most important features of a random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "feat_importance=feat_importance.iloc[0:20,:]\n",
    "# X_train=X_train.loc[:,feat_importance.index]    #  X_train 30 most important features\n",
    "\n",
    "# plot the 50 most important features \n",
    "plt.figure(figsize=(6,8))\n",
    "plt.barh(y=feat_importance.index,width=feat_importance['features']);\n",
    "plt.title(' Featureimportance - TOP 20 , fontsize=16')\n",
    "plt.box(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISTRIBUTION OF THE TARGET VARIABLE - Price of house y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y, bins=None, hist=True, kde=True, rug=False, fit=None, hist_kws=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPARING VARIOUS MACHINE LEARNING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESTABLISHING A BASELINE  -  DUMMY CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# DUMMY CLASSIFIER to serve as the baseline for comparism with the more advanced classification models below\n",
    "grid_dummy=GridSearchCV(DummyRegressor( ), \n",
    "                        param_grid={'strategy':['median']},          # Using the median because the target variable is skewed\n",
    "                        cv=2,\n",
    "                        scoring='r2',\n",
    "                        n_jobs=-1\n",
    "                         )\n",
    "grid_dummy.fit(X_train,y_train)\n",
    "y_predicted_dummy=grid_dummy.predict(X_train)\n",
    "\n",
    "print('\\n R2  score \\t', grid_dummy.score(X_train , y_train),'\\n')\n",
    "pd.DataFrame(grid_dummy.cv_results_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "parameter_Lasso=            dict({ \n",
    "                                            'alpha':np.arange(1,50),\n",
    "                                            'random_state':[0],               \n",
    "                                          })\n",
    "\n",
    "grid_Lasso=GridSearchCV (    \n",
    "                                 Lasso(), \n",
    "                                 cv=2, \n",
    "                                 param_grid=parameter_Lasso,\n",
    "                                 scoring= 'r2',\n",
    "                                 n_jobs= -1\n",
    "                                )\n",
    "\n",
    "grid_Lasso.fit(X_train,y_train)\n",
    "\n",
    "print('R-squared score (training): {:.3f}'.format(grid_Lasso.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}\\n'.format(grid_Lasso.score(X_test, y_test)))\n",
    "\n",
    "y_test_predicted_Lasso=grid_Lasso.predict(X_test)     # using the gridsearchcv object for prediction\n",
    "print('Test RMSE \\t:',np.sqrt(mean_squared_error( y_test, y_test_predicted_Lasso)))\n",
    "\n",
    "# pd.DataFrame(grid_Lasso.cv_results_)       # tabulating the outcome of gridsearchcv object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR REGRESSOR - SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "parameter_SVR=            dict({ \n",
    "                                            'degree':[2,3,4],   \n",
    "                                            'gamma': ['scale','auto'],\n",
    "                                            'kernel':['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                                             'C' : [0.01,0.1,1,2,3,5,10]\n",
    "                                          })\n",
    "\n",
    "grid_SVR=GridSearchCV (    \n",
    "                                 SVR(), \n",
    "                                 cv=2, \n",
    "                                 param_grid=parameter_SVR,\n",
    "                                 scoring= 'r2',\n",
    "                                 n_jobs= -1 \n",
    "                                )\n",
    "\n",
    "grid_SVR.fit(X_train,y_train)\n",
    "\n",
    "print('R-squared score (training): {:.3f}'.format(grid_SVR.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}\\n'.format(grid_SVR.score(X_test, y_test)))\n",
    "\n",
    "y_test_predicted_svr=grid_SVR.predict(X_test)     # using the gridsearchcv object for prediction\n",
    "print('Test RMSE \\t:',np.sqrt(mean_squared_error( y_test, y_test_predicted_svr)))\n",
    "\n",
    "# pd.DataFrame(grid_SVR.cv_results_)       # tabulating the outcome of gridsearchcv object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "parameter_random_forest=            dict({ \n",
    "                                            'n_estimators':[100,150,200,300,400,500],\n",
    "                                            'criterion': ['mse'],\n",
    "                                            'max_features': ['auto'],\n",
    "                                            'bootstrap': [True],\n",
    "                                            'oob_score': [True],\n",
    "                                            'n_jobs' : [-1],\n",
    "                                            'random_state':[0],\n",
    "                                            'warm_start':[False],                \n",
    "                                          })\n",
    "\n",
    "\n",
    "grid_random_forest=GridSearchCV (    \n",
    "                                 RandomForestRegressor(), \n",
    "                                 cv=2, \n",
    "                                 param_grid=parameter_random_forest,\n",
    "                                 scoring= 'r2'\n",
    "                                )\n",
    "\n",
    "grid_random_forest.fit(X_train,y_train)\n",
    "\n",
    "print('R-squared score (training): {:.3f}'.format(grid_random_forest.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}\\n'.format(grid_random_forest.score(X_test, y_test)))\n",
    "\n",
    "y_test_predicted_forest=grid_random_forest.predict(X_test)\n",
    "print('Test RMSE \\t:',np.sqrt(mean_squared_error(y_test, y_test_predicted_forest)))\n",
    "\n",
    "y_predicted=grid_random_forest.predict(X_train)     # using the gridsearchcv object for prediction\n",
    "# pd.DataFrame(grid_random_forest.cv_results_)       # tabulating the outcome of gridsearchcv object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=pd.DataFrame(y_test_predicted_forest,columns=['predicted'])\n",
    "actual=pd.DataFrame(y_test.astype('float64'))\n",
    "com=pd.concat(\n",
    "           [actual.reset_index(drop=True), \n",
    "            predicted.reset_index(drop=True)],\n",
    "            axis=1\n",
    "           )\n",
    "com['Difference']=(com['SalePrice']-com['predicted'])\n",
    "\n",
    "com.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA BOOST REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "parameter_AdaBoost=            dict({ \n",
    "                                            'n_estimators':[100,200,300],\n",
    "                                            'random_state':[0],    \n",
    "                                            'learning_rate': [0.001,0.01,0.1],\n",
    "                                            'loss': ['linear','square','exponential']\n",
    "                                          })\n",
    "\n",
    "grid_AdaBoost=GridSearchCV (    \n",
    "                                 AdaBoostRegressor(), \n",
    "                                 cv=2, \n",
    "                                 param_grid=parameter_AdaBoost,\n",
    "                                 scoring= 'r2',\n",
    "                                 n_jobs= -1 \n",
    "                                )\n",
    "\n",
    "grid_AdaBoost.fit(X_train,y_train)\n",
    "\n",
    "print('R-squared score (training): {:.3f}'.format(grid_AdaBoost.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}\\n'.format(grid_AdaBoost.score(X_test, y_test)))\n",
    "\n",
    "y_test_predicted_AdaBoost=grid_AdaBoost.predict(X_test)      # using the gridsearchcv object for prediction\n",
    "print('Test RMSE \\t:',np.sqrt(mean_squared_error( y_test, y_test_predicted_AdaBoost)))\n",
    "\n",
    "# pd.DataFrame(grid_AdaBoost.cv_results_)       # tabulating the outcome of gridsearchcv object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADIENT BOOSTING REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "parameter_grid_GBR=            dict({ \n",
    "                                            'n_estimators':[100,200,300,600],\n",
    "                                            'criterion': ['friedman_mse'],\n",
    "                                            'max_features': ['auto'],\n",
    "                                            'random_state':[0],    \n",
    "                                            'subsample': [0.85,1.0],\n",
    "                                            'learning_rate': [0.001,0.01,0.1,]\n",
    "                                          })\n",
    "\n",
    "\n",
    "grid_GBR=GridSearchCV (    \n",
    "                                 GradientBoostingRegressor(), \n",
    "                                 cv=2, \n",
    "                                 param_grid=parameter_grid_GBR,\n",
    "                                 scoring= 'r2',\n",
    "                                 n_jobs= -1\n",
    "                                )\n",
    "\n",
    "grid_GBR.fit(X_train,y_train)\n",
    "\n",
    "print('R-squared score (training): {:.3f}'.format(grid_GBR.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}\\n'.format(grid_GBR.score(X_test, y_test)))\n",
    "\n",
    "y_test_predicted_GBR=grid_GBR.predict(X_test)\n",
    "print('Mean Square Error \\t:',np.sqrt(mean_squared_error(y_test, y_test_predicted_GBR)))\n",
    "\n",
    "# pd.DataFrame(grid_GBR.cv_results_)       # tabulating the outcome of gridsearchcv object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOSTING REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameter_XGBoost=            dict({ \n",
    "                                    'objective':['reg:squarederror'],\n",
    "                                    'max_depth':[3,4,5,8,10],\n",
    "                                    'learning_rate' : [0.05,0.01,0.1],\n",
    "                                    'n_estimators':[100,200,300],\n",
    "                                    'gamma':[0,1,2,3],\n",
    "                                    'subsample': [0.9],\n",
    "                                    'colsample_bytree': [1],\n",
    "                                    'reg_alpha' : [0,1,2,3,5,7,10],\n",
    "                                    'scale_pos_weight':[1],\n",
    "                                    'random_state':[0],\n",
    "                                  })\n",
    "\n",
    "grid_XGBoost=GridSearchCV (    \n",
    "                                 XGBRegressor(), \n",
    "                                 cv=2, \n",
    "                                 param_grid=parameter_XGBoost,\n",
    "                                 scoring= 'r2',\n",
    "                                 n_jobs= -1 \n",
    "                                )\n",
    "\n",
    "grid_XGBoost.fit(X_train,y_train)\n",
    "\n",
    "print('R-squared score (training): {:.3f}'.format(grid_XGBoost.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}\\n'.format(grid_XGBoost.score(X_test, y_test)))\n",
    "\n",
    "y_test_predicted_XGBoost=grid_XGBoost.predict(X_test)     # using the gridsearchcv object for prediction\n",
    "print('Test RMSE \\t:',np.sqrt(mean_squared_error( y_test, y_test_predicted_XGBoost)))\n",
    "\n",
    "df_XGBoost=pd.DataFrame(grid_XGBoost.cv_results_)       # tabulating the outcome of gridsearchcv object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=df_XGBoost.sort_values(by=['rank_test_score'])\n",
    "ans.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the ideal parameter values to build the final XGBOOTED model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameter=grid_XGBoost.best_params_\n",
    "best_parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILDING THE OPTIMISED XGBOOSTED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-reading the entire dataset for the to train the optimised model\n",
    "os.chdir(\"c:/Users/User/Desktop/kaggle datasets/housing dataset/\")\n",
    "df=pd.read_csv('house_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the two date columns into years \n",
    "df['YearRemodAdd']=2020-df['YearRemodAdd']\n",
    "df['YearBuilt']=2020-df['YearBuilt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the top 18 features according to their importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>1710</td>\n",
       "      <td>856</td>\n",
       "      <td>2</td>\n",
       "      <td>8450</td>\n",
       "      <td>196.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>65.0</td>\n",
       "      <td>150</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>Y</td>\n",
       "      <td>5</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1262</td>\n",
       "      <td>1262</td>\n",
       "      <td>2</td>\n",
       "      <td>9600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>80.0</td>\n",
       "      <td>284</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>8</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OverallQual  GrLivArea  1stFlrSF  GarageCars  LotArea  MasVnrArea  \\\n",
       "0            7       1710       856           2     8450       196.0   \n",
       "1            6       1262      1262           2     9600         0.0   \n",
       "\n",
       "   YearBuilt  YearRemodAdd  LotFrontage  BsmtUnfSF  TotRmsAbvGrd  MoSold  \\\n",
       "0         17            17         65.0        150             8       2   \n",
       "1         44            44         80.0        284             6       5   \n",
       "\n",
       "   Fireplaces  WoodDeckSF  OpenPorchSF CentralAir  OverallCond  SalePrice  \n",
       "0           0           0           61          Y            5     208500  \n",
       "1           1         298            0          Y            8     181500  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['OverallQual','GrLivArea','1stFlrSF','GarageCars','LotArea','MasVnrArea','YearBuilt','YearRemodAdd','LotFrontage',\n",
    "       'BsmtUnfSF','TotRmsAbvGrd','MoSold','Fireplaces','WoodDeckSF','OpenPorchSF','CentralAir','OverallCond','SalePrice']]\n",
    "\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OverallQual     0\n",
      "GrLivArea       0\n",
      "1stFlrSF        0\n",
      "GarageCars      0\n",
      "LotArea         0\n",
      "MasVnrArea      0\n",
      "YearBuilt       0\n",
      "YearRemodAdd    0\n",
      "LotFrontage     0\n",
      "BsmtUnfSF       0\n",
      "TotRmsAbvGrd    0\n",
      "MoSold          0\n",
      "Fireplaces      0\n",
      "WoodDeckSF      0\n",
      "OpenPorchSF     0\n",
      "CentralAir      0\n",
      "OverallCond     0\n",
      "House_Price     0\n",
      "dtype: int64\n",
      "\n",
      " OverallQual       int64\n",
      "GrLivArea         int64\n",
      "1stFlrSF          int64\n",
      "GarageCars        int64\n",
      "LotArea           int64\n",
      "MasVnrArea      float64\n",
      "YearBuilt         int64\n",
      "YearRemodAdd      int64\n",
      "LotFrontage     float64\n",
      "BsmtUnfSF         int64\n",
      "TotRmsAbvGrd      int64\n",
      "MoSold            int64\n",
      "Fireplaces        int64\n",
      "WoodDeckSF        int64\n",
      "OpenPorchSF       int64\n",
      "CentralAir       object\n",
      "OverallCond       int64\n",
      "House_Price       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Dropping the rows with missing values for MasVnrArea\n",
    "df=df.loc[df['MasVnrArea'].notnull(), : ]\n",
    "\n",
    "# converting LotFrontage to a numeric dtypes\n",
    "df['LotFrontage']=pd.to_numeric(df['LotFrontage'], errors='coerce')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print('\\n',df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LotFrontage']=df['LotFrontage'].replace('.','')\n",
    "df['LotFrontage'].fillna(df['LotFrontage'].mean(),inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating the target variable from the independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['SalePrice']\n",
    "X=df.drop(labels=['SalePrice'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Dataset into train set and test set ( ratio 95 : 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y, random_state=15,test_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_tran=['OverallQual', 'GrLivArea', '1stFlrSF', 'GarageCars', 'LotArea',\n",
    "                                               'MasVnrArea', 'YearBuilt', 'YearRemodAdd', 'LotFrontage', 'BsmtUnfSF',\n",
    "                                               'TotRmsAbvGrd', 'MoSold', 'Fireplaces', 'WoodDeckSF', 'OpenPorchSF','OverallCond','CentralAir']\n",
    "\n",
    "transformed_columns= make_column_transformer (\n",
    "                                               (MinMaxScaler(), \n",
    "                                               ['OverallQual', 'GrLivArea', '1stFlrSF', 'GarageCars', 'LotArea',\n",
    "                                               'MasVnrArea', 'YearBuilt', 'YearRemodAdd', 'LotFrontage', 'BsmtUnfSF',\n",
    "                                               'TotRmsAbvGrd', 'MoSold', 'Fireplaces', 'WoodDeckSF', 'OpenPorchSF','OverallCond'] ),\n",
    "                                                \n",
    "                                                (OneHotEncoder(handle_unknown='error',sparse=False, dtype='float32' , drop='first'),['CentralAir']),\n",
    "                                                remainder = 'passthrough'\n",
    "                                              )\n",
    "\n",
    "# transformer=transformed_columns.fit_transform(X_train)\n",
    "\n",
    "# X_train=pd.DataFrame(transformer,columns=columns_tran)\n",
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE OPTIMISED XGBOOSTED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBRegressor=XGBRegressor (\n",
    "                             colsample_bytree= 1,\n",
    "                             gamma= 0,\n",
    "                             learning_rate= 0.05,\n",
    "                             max_depth= 3,\n",
    "                             n_estimators= 300,\n",
    "                             objective='reg:squarederror',\n",
    "                             random_state=0,\n",
    "                             reg_alpha= 3,\n",
    "                             scale_pos_weight= 1,\n",
    "                             subsample=0.9\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('minmaxscaler',\n",
       "                                                  MinMaxScaler(),\n",
       "                                                  ['OverallQual', 'GrLivArea',\n",
       "                                                   '1stFlrSF', 'GarageCars',\n",
       "                                                   'LotArea', 'MasVnrArea',\n",
       "                                                   'YearBuilt', 'YearRemodAdd',\n",
       "                                                   'LotFrontage', 'BsmtUnfSF',\n",
       "                                                   'TotRmsAbvGrd', 'MoSold',\n",
       "                                                   'Fireplaces', 'WoodDeckSF',\n",
       "                                                   'OpenPorchSF',\n",
       "                                                   'OverallCond']),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(drop='first',\n",
       "                                                                dtype='float32',\n",
       "                                                                sparse=False),\n",
       "                                                  ['CentralAir'])])),\n",
       "                ('xgbregressor',\n",
       "                 XGBRegressor(learning_rate=0.05, n_estimators=300,\n",
       "                              objective='reg:squarederror', reg_alpha=3,\n",
       "                              subsample=0.9))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe=make_pipeline(transformed_columns, XGBRegressor)\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST ON THE OPTIMISED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R-squared score (training): {:.3f}'.format(pipe.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}\\n'.format(pipe.score(X_test, y_test)))\n",
    "\n",
    "y_predicted_train=pipe.predict(X_train)\n",
    "print('Train RMSE \\t:',np.sqrt(mean_squared_error( y_train, y_predicted_train)))\n",
    "\n",
    "y_test_predicted=pipe.predict(X_test)                           \n",
    "print('Test RMSE \\t:',np.sqrt(mean_squared_error( y_test, y_test_predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVING THE MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import os\n",
    "\n",
    "# os.chdir('c://Users/user/.spyder-py3/templates/pickle/')\n",
    "\n",
    "# file=open('model_housePricePrediction_xgboost2020.pkl','wb')\n",
    "# pickle.dump(pipe,file)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>House_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>4</td>\n",
       "      <td>1092</td>\n",
       "      <td>546</td>\n",
       "      <td>1</td>\n",
       "      <td>1974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>70.030126</td>\n",
       "      <td>212</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>96</td>\n",
       "      <td>Y</td>\n",
       "      <td>5</td>\n",
       "      <td>83500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>6</td>\n",
       "      <td>1252</td>\n",
       "      <td>1032</td>\n",
       "      <td>1</td>\n",
       "      <td>9600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>752</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>5</td>\n",
       "      <td>119000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>9</td>\n",
       "      <td>1922</td>\n",
       "      <td>1922</td>\n",
       "      <td>3</td>\n",
       "      <td>14157</td>\n",
       "      <td>200.0</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>673</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>51</td>\n",
       "      <td>Y</td>\n",
       "      <td>5</td>\n",
       "      <td>377426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>6</td>\n",
       "      <td>1212</td>\n",
       "      <td>1212</td>\n",
       "      <td>2</td>\n",
       "      <td>10420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>1176</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>22</td>\n",
       "      <td>Y</td>\n",
       "      <td>5</td>\n",
       "      <td>186000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>8</td>\n",
       "      <td>2466</td>\n",
       "      <td>1580</td>\n",
       "      <td>2</td>\n",
       "      <td>11143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>1580</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>159</td>\n",
       "      <td>214</td>\n",
       "      <td>Y</td>\n",
       "      <td>5</td>\n",
       "      <td>340000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      OverallQual  GrLivArea  1stFlrSF  GarageCars  LotArea  MasVnrArea  \\\n",
       "1086            4       1092       546           1     1974         0.0   \n",
       "1136            6       1252      1032           1     9600         0.0   \n",
       "336             9       1922      1922           3    14157       200.0   \n",
       "211             6       1212      1212           2    10420         0.0   \n",
       "377             8       2466      1580           2    11143         0.0   \n",
       "\n",
       "      YearBuilt  YearRemodAdd  LotFrontage  BsmtUnfSF  TotRmsAbvGrd  MoSold  \\\n",
       "1086         47            47    70.030126        212             6       5   \n",
       "1136         70            70    80.000000        752             6       4   \n",
       "336          15            14    86.000000        673             8       7   \n",
       "211          11            11    83.000000       1176             6       3   \n",
       "377          16            15   102.000000       1580             8      12   \n",
       "\n",
       "      Fireplaces  WoodDeckSF  OpenPorchSF CentralAir  OverallCond  House_Price  \n",
       "1086           0         120           96          Y            5        83500  \n",
       "1136           0           0            0          Y            5       119000  \n",
       "336            1         178           51          Y            5       377426  \n",
       "211            0         100           22          Y            5       186000  \n",
       "377            1         159          214          Y            5       340000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['House_Price']=y_test\n",
    "df=X_test\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
